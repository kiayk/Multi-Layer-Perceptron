# Multi-Layer-Perceptron
Implementing a MLP from scratch for pedagogical purposes.
This Multi Layer Perceptron (MLP) consists of an input layer, a hidden layer and an output layer. The aim of this exercise is to show how the Error Back Propagation (EBP) algorithm can be implemented in an ANN. And compare two methods of batch learning and pattern by pattern learning with each other in terms of convergence rate.

![](https://33333.cdn.cke-cs.com/kSW7V9NHUXugvhoQeFaf/images/3bc0e133c05e404a8c77f0eaf11e9d994bad6e89923c2741.png)
